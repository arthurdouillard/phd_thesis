\chapter{Acronyms}

\begin{acronym}[XXXXXXX]
    \acro{AI}{Artificial Intelligence}
    \acro{BN}{Batch Normalization}
    \acro{ConvNet}[\textlarger{ConvNet}]{Convolutional Neural Network}
    \acro{CV}{Computer Vision}
    \acro{DA}{Data Augmentation}
    \acro{FC}{Fully Connected}
    \acro{DL}{Deep Learning}
    \acro{DNN}{Deep Neural Network}
    \acro{GAN}{Generative Adversarial Network}
    \acro{GPU}{Graphics Processing Unit}
    \acro{ML}{Machine Learning}
    \acro{MLP}{Multi-Layer Perceptron}
    \acro{MSE}{Mean-Squared Error}
    \acro{NN}{Neural Network}
    \acro{ReLU}{Rectified Linear Unit}
    \acro{SGD}{Stochastic Gradient Descent}
    \acro{SIFT}{Scale-Invariant Feature Transform}
    \acro{SSL}{Semi-Supervi\-sed Learning}
    \acro{TPU}{Tensor Processing Unit}
    \acro{LSC}{Local Similarity Classifier}
    \acro{POD}{Pooled Output Distillation}
    \acro{PODNet}{Pooled Output Distillation Network}
    \acro{PLOP}{Pseudo-labeling and LOcal Pod}
    \acro{DyTox}{Dynamic Token Expansion}
    \acro{NC}{New Classes}
    \acro{NI}{New Instances}
    \acro{NIC}{New Instances and Classes}
    \acro{CIL}{Class Incremental Learning}
    \acro{CL}{Continual Learning}
    \acro{ZSL}{ZeroShot-Learning}
    \acro{KL}{Kullback-Leiber divergence}
    \acro{KD}{Knowledge Distillation}
    \acro{NME}{Nearest Mean Examplar}
    \acro{SVM}{Support-Vectors Machine}
    \acro{CSS}{Continual Semantic Segmentation}
\end{acronym}
