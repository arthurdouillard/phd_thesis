\chapter{Conclusion}
\label{chapter:conclusion}

%\minitoc
\chapterwithfigures{\nameref*{chapter:conclusion}}
%\chapterwithtables{\nameref*{chapter:introduction}}

\ifthenelse{\boolean{skipConclusion}}{\endinput}{}

In this final chapter, we summarize the contributions of this thesis, and then
explore the future directions of Continual Learning.

\section{Contributions}

During this thesis, we aim to learn an increasing number of classes with \ac{DL} architectures for
\ac{CV} without forgetting. We design multiple methods to achieve this goal, with a particular
interest on how the visual features of a continual model evolve through time. First, in \autoref{chapter:regularization}, we
investigate how to constrain features while satisfying a rigidity-plasticity trade-off.
Then, in \autoref{chapter:segmentation}, we explore continual approaches for
semantic segmentation. Finally, in \autoref{chapter:dynamic}, we exploit the transformer
architecture in a dynamic framework to condition features per task.

\paragraph{Visual Features regularization} pass

\paragraph{Continual Semantic Segmentation} pass

\paragraph{Dynamic Strategy with Transformers} pass



\section{Future Work}


